% !TEX root = ../main.tex

\begin{abstract}
互联网技术,多媒体技术以及数字成像技术的蓬勃发展导致了网络上图像内容数据的爆炸性增长， 促使了图像检索技术的出现以及日渐成熟。
图像检索旨在从一个大规模的图像数据库中检索出和查询的图片对应的图像数据，是计算机视觉和多媒体检索领域一个核心的研究问题，因为其具有很高的科研价值以及广泛的应用，近些年在研究社区中获得了广泛的关注。
一个典型的图像检索系统包含两个阶段: (1) 表征学习: 学习一个算法提取图片物体的特征，将高维的图片数据映射到地维的特征向量空间。 (2) 度量学习: 使得第一步中学习到的特征向量具备高维图像数据的语义一致性。语义相似的图片的特征向量距离尽量小，相反，语义不同的的图像的特征向量距离尽量大。传统的图像检索使用实值的特征向量来表征图片, 虽然可以取得较高的准确度，但是由于内存占用量高以及检索速度不高, 导致其可扩展性差, 难以应用在对检索速度要求较高的大规模的图像检索场景。 \par
深度哈希是一种利用深度神经网络来进行特征提取，将高维图片数据映射到低维二进制向量空间的技术，因为其具有内存占用量低，并且检索速度快等优点而被广泛应用在图像检索领域来提高图像检索系统的可扩展性。本文致力于探究深度哈希算法在图像检索领域的应用，提高检索系统的精度和可扩展性。通过探究新型神经网络结构在检索技术中的应用来提高表征能力，以及探究新型度量学习在深度哈希技术中的应用， 本文提出了若干应用于图像检索领域的新型算法。 本文的主要创新点和贡献主要在以下几点:

\begin{enumerate}
  \item 本文对图像检索的一个典型应用-行人重识别问题进行了深入的探讨。传统的行人重识别问题针对单模态的数据,也就是检索的图片和数据库中的图片来自同一模态。而现实中的监控摄像头一般能同时在日间和夜间工作捕捉不同模态的行人照片,这使得跨模态行人重识别成为计算机视觉领域一个热门的研究课题。由于模态鸿沟的存在（Modality Gap）, 跨模态行人重识别比单模态行人重识别更具有挑战性。传统基于双流卷积神经网络的算法,很难学习到模态恒定（Modality-invariant）的特征。针对这一难点,本文创新性的基于自编码器（Autoencoder）设计了一个神经网络架构学习模态恒定以及外表恒定的特征。同时设计了适用于跨模态检索对其不同模态特征的损失函数,使得网络可以在动态创建的图片对上进行监督训练。我们在标准的跨模态重识别数据集上进行了训练以及测试,结果表明我们的算法可以取得优越的性能数据,证明了算法的有效性。
  \item 本文首次将深度哈希引入了大规模车辆检索的研究中。传统基于实值向量检索的车辆重识别算法虽然精度高,但是由于其存储效率低以及检索速度慢,无法适用于真实环境的大规模车辆检索。为了提高车辆检索的速度以及优化存储开销,本文第一个探索了深度哈希在大规模车辆检索中的应用。本文提出一个新型的离散哈希模块,通过同时使用传统的基于困难三元组的损失函数进行特征学习,以及离散哈希模块生成离散的汉明哈希码。为了优化离散的哈希架构,我们提出了一个交替优化算法来进行整个架构的优化。 本文在主流的车辆重识别数据集上进行了四种不同长度哈希码的精度测试,显著的超越了当前的普适的哈希算法。
  \item 为了进一步优化深度哈希算法的表征能力,我们第一次探索一个不基于卷积神经神经网络的深度哈希框架。视觉转换器（Vision Transformer）是一种基于自注意力机制（self-attention）的新型的计算机视觉基础网络模型。本文提出了第一个完全基于视觉转换器的深度哈希框架,通过设计一个孪生视觉转换器架构,以及一个新型的双流特征学习的视觉转换器模块来进行细粒度表征学习。 同时,我们采取成对的基于贝叶斯的学习框架进行度量学习。本文在三个标准化的图像检索基准数据集上进行测试,实验效果表明该方法可以大幅度提升检索的性能。
  \item 由于基于传统哈希编码的方法会带来较大的精度损失,本文探索一种基于乘积量化（Product Quantization）编码的深度哈希算法来提高检索性能。同时,本文提出第一个基于视觉转换器的乘积量化神经网络。为了进行细粒度的特征学习,考虑到视觉转换器的性能与采取的图片分块策略紧耦合的特点,本文设计了一个双支视觉转换器量化的支柱网络。同时,本文设计了一个基于排序损失的直接优化平均查准率 （Average Precision）的量化损失函数来进行度量学习。文章将乘积量化集成到端到端的神经网络优化中,取得了优异的性能表现。
\end{enumerate}


\end{abstract}

\begin{abstract*}
The remarkable advancements in internet , multimedia  and digital imaging technologies have prompted the explosive growth of multimedia data on the internet, which has spurred the advent and the rapid development of image retrieval technologies. Image retrieval is a key research topic in computer vision and multimedia retrieval which targets at retrieving the corresponding image in a large image datab ase given a specific query target. Substantial attention has been drawn to the research of image retrieval in the community given its notable research value and its widespread application in the industry. A common learning paradigm of image retrieval typically incoporates two phases. (1) representation learning: It aims to learn discriminative feature representation from the image data, mapping the high-dimensional image data into low-dimensional feature vector space.  (2) metric learning: it targets at preserving the semantic consistency of the images in the low-dimensional feature space. The projected feature vectors of the semantically-similar images should be pulled as close as possible while those of  dissimilar images be pushed far away. Conventional image retrieval methods generally adopt real-valued feature vectors which enjoy the merit of being sufficently accurate. Nontheless, their high storage costs and low retrieval speed have limited their applicability in a large-scale image retrieval setting where the retrieval speed is of critical importance. \par
Deep hashing is a pervasive technology which has been widespredly applied in image retrieval to promote the scalability of existing retrieval systems owing to its low memory usage and fast retrieval speed. Generally, it transforms high-dimensional image data into low-dimensional compact binary codes with deep neural networks. This dissertation focus on investigating the application of deep hashing technology in image retrieval to boost the accuracy and the scalability of existing retrieval systems.  By exploring novel deep learning architectures and metric learning algorithms, we propose several novel algorithms for large-scale image retrieval. The main novelties and contributions are stated as follows:
\begin{enumerate}
  \item We conduct in-depth research on a typical application of image retrieval - person re-identification. Conventional person re-identification focus on visible images captured by single-modality survelliance cameras. However, these visible light cameras fail to produce high-quality images under poor illumination conditions. Nowadays, the majority of the survelliance cameras are capable of automatically switching from visible to the infrared mode when the illumination condition is poor. This stimulates the researches on visible-infrared cross-modality person re-identification. The existence of the modality gap makes cross-modality person re-identification even more challenging. Previous methods with dual-stream convolutional neural networks generally fail to capture the modality-invariant features. To this end, we devise a novel modality and apperance invariant embedding learning framework for discriminative feature learning, which is equipped with retrofitted loss function for intra-modality and cross-modality retrieval. We conduct extensive experiments on standardized benchmark datasets which have evidenced the superiority of our proposed method.
  \item We make the very first attempt to adopt deep hashing learning to tackle large-scale vehicle retrieval problem. Conventional methods with real-valued feature vectors generally consume tremendous memory and computation, making them inapplicable in a real-world large-scale retrieval scenario. To enhance the retrieval speed and optimize the storage cost, we propose a deep hashing based vehicle re-identification framework.  Specifically, we propose a novel discrete hashing module, which could produce discrete hashing codes combined with the traditional feature learning module with hard-mining triplet loss. To optimize the overall architecture, we propose an alternating minimization method for similarity-preserving hashing codes learning.  Comprehensice experiments on standard vehicle re-identification datasets have demonstrated our effectiveness and efficiency in terms of four hashing code lengths.
  \item To further enhance the representation ability of current deep hashing algorithms, we explore the possibilty of devising a deep hashing framework without convolutional neural networks. Vision transformer is variant of transformer tailored for computer vision tasks, which is based on the self-attention mechanism. We introduce the first deep hashing framework based on pure vision transformer. We design a siamese vision transformer backbone for feature extraction and innovate a novel dual-stream feature learning block to learn discriminative global and local features. In addition, we adopt a bayesian learning scheme with a dynamic constructed similarity matrix for similarity-preserving learning. We performed experiments on three benchmark datasets and the results have evidenced our superiority against the state-of-the-art deep hashing methods.
  \item Traditional hashing encoding scheme will result in considerable performance declines. To mitigate this problem,  we investigate a deep hashing algorithm based on product quantization to boost the retrieval performance. We propose the fist product quantization network based on vision transformer. Motivated by the fact that the performance of vision transformer is closely-related with the patching strategy, we put forward the a dual-brnach vision transformer-based quantization network. In addition, we innovate a novel quantization loss, dubbed average precision quantization loss, which embedbed the asymmetric retrieval nature in product quantization-based methods into the metric learning process. The experiments on widely-studied benchmarks have demonstrated the effectiveness and superiority of our proposed quantization-based framework.
\end{enumerate}
\end{abstract*} 

